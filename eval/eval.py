import json
import random
import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score

# ğŸ”¹ Seed ê³ ì • (ì¼ê´€ëœ ê²°ê³¼ ë³´ì¥)
def set_seed(seed=42):
    np.random.seed(seed)
    random.seed(seed)

set_seed()

# ğŸ”¹ JSON íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
def load_json(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)

# ğŸ”¹ ì¶”ë¡ ëœ ì»¤ë¦¬í˜ëŸ¼(JSONì—ì„œ name & department_name ê°’ ê°€ì ¸ì˜´)
def get_predicted_courses(pred_json_path):
        ground_truth_data = load_json(pred_json_path)
        
        ground_truth_names = set()
        ground_truth_departments = set()

        for course in ground_truth_data:
            course_names = course["course_name"]
            department_names = course["department"]  # í•™ê³¼ ì •ë³´ ì¶”ê°€

            # ğŸ”¹ ê³¼ëª©ëª…ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬ (ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ë§ìœ¼ë©´ ì •ë‹µ)
            if isinstance(course_names, list):  
                ground_truth_names.add(frozenset(course_names))  # ë¦¬ìŠ¤íŠ¸ë¥¼ frozensetìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            else:
                ground_truth_names.add(course_names)  # ë‹¨ì¼ ê³¼ëª© ì¶”ê°€
            
            # ğŸ”¹ í•™ê³¼ëª…ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬ (ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ë§ìœ¼ë©´ ì •ë‹µ)
            if isinstance(department_names, list):  
                ground_truth_departments.add(frozenset(department_names))  # ë¦¬ìŠ¤íŠ¸ë¥¼ frozensetìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            else:
                ground_truth_departments.add(department_names)  # ë‹¨ì¼ í•™ê³¼ ì¶”ê°€
                
        # ğŸ”¥ ë‹¨ì¼ í•™ê³¼ì™€ ê²¹ì¹˜ëŠ” frozenset ì œê±°
        final_departments = set()
        single_departments = {dept for dept in ground_truth_departments if isinstance(dept, str)}

        for dept in ground_truth_departments:
            if isinstance(dept, frozenset):  # í•™ê³¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ ê²½ìš°
                # ğŸ”¹ frozenset ë‚´ë¶€ í•™ê³¼ê°€ ì´ë¯¸ ë‹¨ì¼ í•™ê³¼ì— í¬í•¨ë˜ë©´ ì œì™¸
                if not dept.intersection(single_departments):  
                    final_departments.add(dept)
            else:
                final_departments.add(dept)

        return ground_truth_names, final_departments

# ğŸ”¹ ì •ë‹µ ì»¤ë¦¬í˜ëŸ¼(JSONì—ì„œ course_name & department ê°’ ê°€ì ¸ì˜´)
def get_ground_truth_courses(gt_json_path):
    ground_truth_data = load_json(gt_json_path)
    
    ground_truth_names = set()
    ground_truth_departments = set()

    for course in ground_truth_data:
        course_names = course["course_name"]
        department_names = course["department"]  # í•™ê³¼ ì •ë³´ ì¶”ê°€

        # ğŸ”¹ ê³¼ëª©ëª…ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬ (ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ë§ìœ¼ë©´ ì •ë‹µ)
        if isinstance(course_names, list):  
            ground_truth_names.add(frozenset(course_names))  # ë¦¬ìŠ¤íŠ¸ë¥¼ frozensetìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        else:
            ground_truth_names.add(course_names)  # ë‹¨ì¼ ê³¼ëª© ì¶”ê°€
        
        # ğŸ”¹ í•™ê³¼ëª…ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬ (ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ë§ìœ¼ë©´ ì •ë‹µ)
        if isinstance(department_names, list):  
            ground_truth_departments.add(frozenset(department_names))  # ë¦¬ìŠ¤íŠ¸ë¥¼ frozensetìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        else:
            ground_truth_departments.add(department_names)  # ë‹¨ì¼ í•™ê³¼ ì¶”ê°€
            
    # ğŸ”¥ ë‹¨ì¼ í•™ê³¼ì™€ ê²¹ì¹˜ëŠ” frozenset ì œê±°
    final_departments = set()
    single_departments = {dept for dept in ground_truth_departments if isinstance(dept, str)}

    for dept in ground_truth_departments:
        if isinstance(dept, frozenset):  # í•™ê³¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ ê²½ìš°
            # ğŸ”¹ frozenset ë‚´ë¶€ í•™ê³¼ê°€ ì´ë¯¸ ë‹¨ì¼ í•™ê³¼ì— í¬í•¨ë˜ë©´ ì œì™¸
            if not dept.intersection(single_departments):  
                final_departments.add(dept)
        else:
            final_departments.add(dept)

    return ground_truth_names, final_departments

# ğŸ”¹ Precision, Recall, F1-score ê³„ì‚° í•¨ìˆ˜ (ê³¼ëª©ëª… í‰ê°€)
def calculate_metrics_for_names(predicted_names, ground_truth_names):
    true_positives = predicted_names & ground_truth_names  # êµì§‘í•©
    false_positives = predicted_names - ground_truth_names  # ì˜ˆì¸¡í–ˆì§€ë§Œ ì •ë‹µì´ ì•„ë‹˜
    false_negatives = ground_truth_names - predicted_names  # ì •ë‹µì´ì§€ë§Œ ì˜ˆì¸¡í•˜ì§€ ëª»í•¨

    precision = len(true_positives) / (len(true_positives) + len(false_positives)) if predicted_names else 0
    recall = len(true_positives) / (len(true_positives) + len(false_negatives)) if ground_truth_names else 0
    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0

    return precision, recall, f1

# ğŸ”¹ Precision, Recall, F1-score ê³„ì‚° í•¨ìˆ˜ (í•™ê³¼ í‰ê°€)
def calculate_metrics_for_departments(predicted_departments, ground_truth_departments):
    true_positives = predicted_departments & ground_truth_departments  # êµì§‘í•©
    false_positives = predicted_departments - ground_truth_departments  # ì˜ˆì¸¡í–ˆì§€ë§Œ ì •ë‹µì´ ì•„ë‹˜
    false_negatives = ground_truth_departments - predicted_departments  # ì •ë‹µì´ì§€ë§Œ ì˜ˆì¸¡í•˜ì§€ ëª»í•¨

    precision = len(true_positives) / (len(true_positives) + len(false_positives)) if predicted_departments else 0
    recall = len(true_positives) / (len(true_positives) + len(false_negatives)) if ground_truth_departments else 0
    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0

    return precision, recall, f1

# ğŸ”¹ í‰ê°€ ì‹¤í–‰ í•¨ìˆ˜
def evaluate(pred_json, gt_json):
    """
    í‰ê°€ ì‹¤í–‰ í•¨ìˆ˜ (ê³¼ëª©ëª… & í•™ê³¼ëª… ê°œë³„ í‰ê°€)
    - return: (ê³¼ëª©ëª… precision, recall, f1), (í•™ê³¼ precision, recall, f1)
    """
    predicted_names, predicted_departments = get_predicted_courses(pred_json)
    print(f"predictd_courses ::: {predicted_names}")
    print(f"predicted_departments ::: {predicted_departments}\n\n")
    
    ground_truth_names, ground_truth_departments = get_ground_truth_courses(gt_json)
    print(f"ground_truth_courses :: {ground_truth_names}")
    print(f"ground_truth_departments :: {ground_truth_departments}\n\n")
    print("="*50)

    # ğŸ”¹ ê³¼ëª©ëª… í‰ê°€
    name_precision, name_recall, name_f1 = calculate_metrics_for_names(predicted_names, ground_truth_names)

    # ğŸ”¹ í•™ê³¼ í‰ê°€
    dept_precision, dept_recall, dept_f1 = calculate_metrics_for_departments(predicted_departments, ground_truth_departments)

    return name_precision, name_recall, name_f1, dept_precision, dept_recall, dept_f1


